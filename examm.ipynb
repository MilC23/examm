{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83300804-3674-440f-b40d-8760011bebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Downloading psycopg2-2.9.9-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB 217.9 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.0/1.2 MB 187.9 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.0/1.2 MB 187.9 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.0/1.2 MB 178.6 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.1/1.2 MB 252.2 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.2 MB 327.7 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 379.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.2/1.2 MB 456.4 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.2/1.2 MB 529.7 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.2 MB 610.3 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.4/1.2 MB 735.7 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 842.4 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 891.2 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.7/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.9/1.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.0/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea58a036-474e-43bf-b640-cbbfae457943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database!\n",
      "(1, 'economy', 150, datetime.date(2024, 5, 5), 25, 'Male', 'Nairobi')\n",
      "(2, 'business', 300, datetime.date(2024, 8, 11), 38, 'Female', 'Nakuru')\n",
      "(5, 'economy', 150, datetime.date(2024, 5, 5), 25, 'Feale', 'Naivasha')\n",
      "(6, 'business', 300, datetime.date(2024, 8, 11), 38, 'Male', 'Kitui')\n",
      "(25, 'business', 300, datetime.date(2024, 12, 12), 45, 'Male', 'Kapsabet')\n",
      "(26, 'business', 300, datetime.date(2023, 11, 8), 38, 'Female', 'Narok')\n",
      "(27, 'economy', 150, datetime.date(2023, 9, 7), 27, 'Female', 'Kisumu')\n",
      "(28, 'business', 300, datetime.date(2024, 11, 10), 18, 'Female', 'Diani')\n",
      "(3, 'economy', 150, datetime.date(2023, 7, 9), 25, 'Male', 'Kisumu')\n",
      "(4, 'business', 300, datetime.date(2024, 10, 11), 38, 'Female', 'Mombasa')\n",
      "(24, 'economy', 150, datetime.date(2024, 8, 5), 25, 'Female', 'Naivasha')\n",
      "(53, 'business', 300, datetime.date(2024, 12, 12), 65, 'Male', 'Eldoret')\n",
      "(54, 'business', 300, datetime.date(2023, 11, 8), 48, 'Female', 'Nakuru')\n",
      "(55, 'economy', 150, datetime.date(2023, 9, 27), 77, 'Female', 'Kigali')\n",
      "(56, 'business', 300, datetime.date(2023, 10, 18), 48, 'Female', 'Daresalaam')\n",
      "(57, 'business', 300, datetime.date(2024, 12, 19), 36, 'Female', 'Mwanza')\n",
      "(58, 'business', 300, datetime.date(2023, 11, 22), 46, 'Male', 'Lamu')\n",
      "(59, 'economy', 150, datetime.date(2024, 9, 21), 79, 'Male', 'Kampala')\n",
      "(60, 'business', 300, datetime.date(2024, 12, 17), 38, 'Male', 'Malindi')\n",
      "(61, 'business', 300, datetime.date(2023, 11, 22), 45, 'Female', 'Jinja')\n",
      "(62, 'business', 300, datetime.date(2024, 9, 18), 38, 'Male', 'Turkana')\n",
      "(63, 'economy', 150, datetime.date(2023, 9, 11), 87, 'Male', 'Bujumbura')\n",
      "(64, 'business', 300, datetime.date(2023, 11, 3), 38, 'Male', 'Kilifi')\n",
      "(65, 'business', 300, datetime.date(2024, 12, 2), 45, 'Female', 'Homabay')\n",
      "(66, 'business', 300, datetime.date(2023, 11, 27), 68, 'Male', 'Narok')\n",
      "(67, 'economy', 150, datetime.date(2024, 9, 12), 97, 'Male', 'Kijabe')\n",
      "(68, 'business', 300, datetime.date(2024, 11, 1), 69, 'Female', 'Kisumu')\n",
      "(69, 'business', 300, datetime.date(2023, 12, 2), 35, 'Male', 'Karachuonyo')\n",
      "(70, 'business', 300, datetime.date(2023, 11, 19), 88, 'Male', 'Naivasha')\n",
      "(71, 'economy', 150, datetime.date(2024, 9, 26), 67, 'Female', 'Homabay')\n",
      "(72, 'business', 300, datetime.date(2024, 6, 15), 38, 'Female', 'Malindi')\n",
      "(73, 'business', 300, datetime.date(2024, 7, 12), 45, 'Female', 'Nyali')\n",
      "(74, 'business', 300, datetime.date(2024, 8, 28), 78, 'Female', 'Lamu')\n",
      "(75, 'economy', 150, datetime.date(2023, 11, 27), 27, 'Male', 'Kisumu')\n",
      "(76, 'business', 300, datetime.date(2023, 9, 15), 68, 'Male', 'Mwanza')\n",
      "(77, 'business', 300, datetime.date(2024, 2, 12), 35, 'Male', 'Kilifi')\n",
      "(78, 'business', 300, datetime.date(2023, 11, 29), 78, 'Female', 'Jinja')\n",
      "(79, 'economy', 150, datetime.date(2024, 9, 26), 27, 'Male', 'Machakos')\n",
      "(80, 'business', 300, datetime.date(2024, 11, 1), 38, 'Female', 'Eldoret')\n",
      "(81, 'business', 300, datetime.date(2023, 12, 22), 65, 'Male', 'Bujumbura')\n",
      "(82, 'business', 300, datetime.date(2023, 11, 8), 78, 'Female', 'Narok')\n",
      "(83, 'economy', 150, datetime.date(2024, 9, 27), 77, 'Female', 'Kilifi')\n",
      "(84, 'business', 300, datetime.date(2024, 10, 10), 58, 'Female', 'Diani')\n",
      "(85, 'business', 300, datetime.date(2023, 12, 9), 36, 'Female', 'Kambiti')\n",
      "(86, 'business', 300, datetime.date(2023, 11, 12), 66, 'Male', 'Dodoma')\n",
      "(87, 'economy', 150, datetime.date(2023, 9, 21), 59, 'Male', 'Kampala')\n",
      "(88, 'business', 300, datetime.date(2024, 12, 17), 18, 'Male', 'Jinja')\n",
      "(89, 'business', 300, datetime.date(2023, 11, 12), 25, 'Female', 'Kapsabet')\n",
      "(90, 'business', 300, datetime.date(2023, 9, 8), 28, 'Male', 'Turkana')\n",
      "(91, 'economy', 150, datetime.date(2023, 9, 11), 47, 'Male', 'Kigali')\n",
      "(92, 'business', 300, datetime.date(2023, 11, 13), 58, 'Male', 'Mwanza')\n",
      "(93, 'business', 300, datetime.date(2024, 12, 22), 25, 'Female', 'Homabay')\n",
      "(94, 'business', 300, datetime.date(2023, 11, 17), 48, 'Male', 'Narok')\n",
      "(95, 'economy', 150, datetime.date(2024, 9, 30), 67, 'Male', 'Kijabe')\n",
      "(96, 'business', 300, datetime.date(2024, 11, 21), 49, 'Female', 'Daresalaam')\n",
      "(97, 'business', 300, datetime.date(2024, 12, 22), 35, 'Male', 'Karachuonyo')\n",
      "(98, 'business', 300, datetime.date(2023, 11, 29), 18, 'Male', 'Naivasha')\n",
      "(99, 'economy', 150, datetime.date(2023, 9, 16), 37, 'Female', 'Narobi')\n",
      "(100, 'business', 300, datetime.date(2023, 6, 21), 68, 'Female', 'Diani')\n",
      "(29, 'business', 300, datetime.date(2024, 12, 9), 56, 'Female', 'Kambiti')\n",
      "(30, 'business', 300, datetime.date(2023, 11, 2), 76, 'Male', 'Dodoma')\n",
      "(31, 'economy', 150, datetime.date(2023, 9, 1), 19, 'Male', 'Kampala')\n",
      "(32, 'business', 300, datetime.date(2024, 12, 7), 68, 'Male', 'Jinja')\n",
      "(33, 'business', 300, datetime.date(2024, 11, 12), 55, 'Female', 'Kapsabet')\n",
      "(34, 'business', 300, datetime.date(2023, 9, 8), 48, 'Male', 'Turkana')\n",
      "(35, 'economy', 150, datetime.date(2023, 9, 1), 67, 'Male', 'Kigali')\n",
      "(36, 'business', 300, datetime.date(2024, 11, 3), 98, 'Male', 'Mwanza')\n",
      "(37, 'business', 300, datetime.date(2024, 12, 2), 35, 'Female', 'Homabay')\n",
      "(38, 'business', 300, datetime.date(2023, 11, 7), 38, 'Male', 'Narok')\n",
      "(39, 'economy', 150, datetime.date(2023, 9, 12), 27, 'Male', 'Kijabe')\n",
      "(40, 'business', 300, datetime.date(2024, 11, 11), 19, 'Female', 'Daresalaam')\n",
      "(41, 'business', 300, datetime.date(2024, 12, 2), 25, 'Male', 'Karachuonyo')\n",
      "(42, 'business', 300, datetime.date(2023, 11, 9), 58, 'Male', 'Naivasha')\n",
      "(43, 'economy', 150, datetime.date(2023, 9, 6), 67, 'Female', 'Narobi')\n",
      "(44, 'business', 300, datetime.date(2024, 6, 10), 78, 'Female', 'Diani')\n",
      "(45, 'business', 300, datetime.date(2024, 7, 12), 35, 'Female', 'Lamu')\n",
      "(46, 'business', 300, datetime.date(2023, 8, 8), 38, 'Female', 'Malindi')\n",
      "(47, 'economy', 150, datetime.date(2023, 11, 7), 77, 'Male', 'Kisumu')\n",
      "(48, 'business', 300, datetime.date(2024, 9, 10), 78, 'Male', 'Goma')\n",
      "(49, 'business', 300, datetime.date(2024, 2, 12), 45, 'Male', 'Bujumbura')\n",
      "(50, 'business', 300, datetime.date(2023, 11, 9), 58, 'Female', 'Kakamega')\n",
      "(51, 'economy', 150, datetime.date(2023, 9, 6), 67, 'Male', 'Machakos')\n",
      "(52, 'business', 300, datetime.date(2024, 11, 11), 28, 'Female', 'Diani')\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection parameters\n",
    "dbname = \"allSQLDatabases\"\n",
    "user = \"postgres\"\n",
    "password = \"1234567890\"\n",
    "host = \"127.0.0.1\"\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the database\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    print(\"Connected to the database!\")\n",
    "\n",
    "    # Create a cursor object using the connection\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute SQL query\n",
    "    cursor.execute(\"SELECT * FROM ticket_sales\")\n",
    "\n",
    "    # Fetch all rows from the result\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Process or manipulate the data as needed\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    # Close the cursor and the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to the database:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523b2e3a-dfe0-415d-8ac4-7718c1e96f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database!\n",
      "Number of null values in departure_date column: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "def count_null_departure_dates(dbname, user, password, host, table_name):\n",
    "    try:\n",
    "        # Establish a connection to the database\n",
    "        conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "        print(\"Connected to the database!\")\n",
    "\n",
    "        # Create a cursor object using the connection\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute SQL query to count null values in departure_date column\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name} WHERE departure_date IS NULL\")\n",
    "\n",
    "        # Fetch the count\n",
    "        null_count = cursor.fetchone()[0]\n",
    "        print(\"Number of null values in departure_date column:\", null_count)\n",
    "\n",
    "        # Close the cursor and the connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        return null_count\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "\n",
    "# Example usage\n",
    "dbname = \"allSQLDatabases\"\n",
    "user = \"postgres\"\n",
    "password = \"1234567890\"\n",
    "host = \"127.0.0.1\"\n",
    "table_name = \"ticket_sales\"\n",
    "\n",
    "count_null_departure_dates(dbname, user, password, host, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56638d31-19be-4df8-bb4a-62fd57f52f76",
   "metadata": {},
   "source": [
    "Define the Problem:\r\n",
    "The problem is to predict the fare based on ticket type, customer age, and customer region using regression analysis. This involves finding the relationship between the dependent variable (fare) and the independent variables (ticket type, customer age, and customer region)\n",
    "The hypothesis\n",
    "Customer_region,departure_date,ticket_time are the predictor variables affects fare which is a dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a84cf8-9212-4c62-a1fc-c44cd1dc000b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ticket_sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load dataset (example)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Replace 'data.csv' with the path to your dataset\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticket_sales.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Preprocessing\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Handle missing values (if any)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ticket_sales.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset (example)\n",
    "# Replace 'data.csv' with the path to your dataset\n",
    "data = pd.read_csv('ticket_sales.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# Handle missing values (if any)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data['ticket_type'] = label_encoder.fit_transform(data['ticket_type'])\n",
    "data['customer_region'] = label_encoder.fit_transform(data['customer_region'])\n",
    "\n",
    "# Scale numerical variables\n",
    "scaler = StandardScaler()\n",
    "data['customer_age'] = scaler.fit_transform(data['customer_age'].values.reshape(-1, 1))\n",
    "\n",
    "# Split dataset into features and target variable\n",
    "X = data[['ticket_type', 'customer_age', 'customer_region']]\n",
    "y = data['fare']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose Model and Train Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded6b41-1069-4c8f-b940-496a4d86ac57",
   "metadata": {},
   "source": [
    "The dependent variable fare is affected by the individual predictor variables stated above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
